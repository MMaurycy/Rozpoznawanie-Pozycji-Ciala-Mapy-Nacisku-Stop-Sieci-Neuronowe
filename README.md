# Rozpoznawanie Pozycji CiaÅ‚a na Podstawie Map Nacisku Stopy przy UÅ¼yciu Sieci Neuronowych

**Autor:** Marcin Przybylski
**Data:** 1 maja 2025

## Opis Projektu

Niniejszy projekt badawczy dotyczy zastosowania sieci neuronowych do klasyfikacji pozycji ciaÅ‚a czÅ‚owieka â€“ stanie, skÅ‚on, przysiad â€“ na podstawie danych z map rozkÅ‚adu nacisku stÃ³p. Dane wejÅ›ciowe to obrazy o wymiarach $18 \times 34$ pikseli, reprezentujÄ…ce rozkÅ‚ad nacisku na podÅ‚oÅ¼e. GÅ‚Ã³wnym celem projektu byÅ‚o porÃ³wnanie efektywnoÅ›ci dwÃ³ch architektur sieci neuronowych: w peÅ‚ni poÅ‚Ä…czonej sieci neuronowej (FCN) oraz konwolucyjnej sieci neuronowej (CNN). Dodatkowo, projekt eksplorowaÅ‚ wpÅ‚yw technik optymalizacyjnych, takich jak normalizacja wsadowa (Batch Normalization), zwiÄ™kszenie liczby filtrÃ³w, augmentacja danych (Data Augmentation) oraz dynamiczna redukcja wspÃ³Å‚czynnika uczenia (Learning Rate Scheduling) na wydajnoÅ›Ä‡ modelu CNN.

## ğŸ“‚ Struktura Projektu

Prace zostaÅ‚y zrealizowane w Å›rodowisku Google Colaboratory, z wykorzystaniem jÄ™zyka Python i bibliotek TensorFlow/Keras.


## âš™ï¸ Metodologia

### 1. Wczytywanie i Przygotowanie Danych

Dane wejÅ›ciowe (mapy nacisku stÃ³p i etykiety pozycji ciaÅ‚a) pobrano ze zdalnego serwera w formacie plikÃ³w `.npy`. DostÄ™pne byÅ‚y oddzielne zbiory treningowy i testowy.

* **KsztaÅ‚ty danych (po transpozycji):**
    * Treningowe (cechy): (5416, 18, 34)
    * Testowe (cechy): (744, 18, 34)
    * Treningowe (etykiety): (5416, 1)
    * Testowe (etykiety): (744, 1)
* **Mapowanie klas:** 0 - Przysiad, 1 - SkÅ‚on, 2 - Stanie.
* **Kroki przetwarzania wstÄ™pnego:**
    * Transpozycja wymiarÃ³w cech do formatu (liczba\_obrazÃ³w, wysokoÅ›Ä‡, szerokoÅ›Ä‡).
    * Normalizacja wartoÅ›ci pikseli do zakresu [0, 1].
    * SpÅ‚aszczenie obrazÃ³w $18 \times 34$ do wektorÃ³w 612 cech dla FCN.
    * Zmiana ksztaÅ‚tu danych wejÅ›ciowych do (18, 34, 1) dla CNN.
    * Kodowanie "one-hot" etykiet klas.
    * PodziaÅ‚ zbioru treningowego na wÅ‚aÅ›ciwy zbiÃ³r treningowy (85%) i walidacyjny (15%) z stratyfikacjÄ… (random\_state=173201). ZbiÃ³r testowy pozostaÅ‚ nienaruszony.

### 2. Architektury Modeli

* **Model FCN (W PeÅ‚ni PoÅ‚Ä…czony):**
    * Warstwa wejÅ›ciowa dla 612 cech.
    * Dwie ukryte warstwy gÄ™ste (Dense) po 7 neuronÃ³w z aktywacjÄ… ReLU, kaÅ¼da poprzedzona warstwÄ… Dropout (0.1).
    * Warstwa wyjÅ›ciowa Dense z 3 neuronami (liczba klas) i aktywacjÄ… Softmax.
* **Model CNN (Bazowy):**
    * Warstwa Conv2D (4 filtry, kernel 3x3, ReLU, padding 'valid') â†’ MaxPooling2D (2x2).
    * Warstwa Conv2D (4 filtry, kernel 3x3, ReLU, padding 'valid') â†’ MaxPooling2D (2x2).
    * Warstwa Conv2D (4 filtry, kernel 3x3, ReLU, padding 'valid').
    * Warstwa Flatten.
    * Warstwa Dense (16 neuronÃ³w, ReLU).
    * Warstwa Dropout (0.2).
    * Warstwa wyjÅ›ciowa Dense (3 neurony, Softmax).
* **Modele CNN (Optymalizacje):**
    * **CNN v2 (BatchNorm, More Filters):** Dodano Batch Normalization po Conv2D i Dense. ZwiÄ™kszono liczbÄ™ filtrÃ³w w Conv2D (8, 16, 32) i neuronÃ³w w Dense (32). Dropout zwiÄ™kszony do 0.3.
    * **CNN v3 (Augmentation):** BazujÄ…c na v2, dodano warstwy augmentacji danych (RandomFlip, RandomRotation, RandomZoom).
    * **CNN v4 (LR Scheduling):** Architektura jak v3, z zastosowaniem callbacku `ReduceLROnPlateau` podczas treningu.

### 3. Proces Treningu

* **Kompilacja:** Optymalizator Adam, funkcja straty `categorical_crossentropy`, metryka `accuracy`.
* **Trening FCN i bazowego CNN:**
    1.  Trening wstÄ™pny (500 epok) do identyfikacji optymalnej liczby epok na podstawie `val_loss`.
    2.  Trening ostateczny z resetem wag przez wyznaczonÄ… liczbÄ™ epok.
* **Trening modeli optymalizacyjnych (v2, v3, v4):** Liczba epok bazujÄ…ca na optymalnej dla bazowego CNN (v2 tak samo; v3, v4 podwojona liczba dla nowego `random_state`).
* **Rozmiar wsadu (batch\_size):** 32.

### 4. Ewaluacja Modeli

* Ocena na zbiorze testowym.
* Metryki: DokÅ‚adnoÅ›Ä‡ (Accuracy), Strata (Loss).
* Analiza macierzy pomyÅ‚ek.
* Wizualizacja krzywych uczenia.

## ğŸ› ï¸ Wykorzystane NarzÄ™dzia i Technologie

* **JÄ™zyk programowania:** Python
* **Biblioteki:**
    * TensorFlow/Keras
    * NumPy
    * Scikit-learn (train\_test\_split, metryki oceny)
    * Matplotlib/Seaborn (wizualizacje)
    * Requests (pobieranie danych)
* **Åšrodowisko:** Google Colaboratory

## ğŸ“Š Wyniki i Interpretacja (random_state = 173201)

### Model FCN
* DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 52.55%
* Strata na zbiorze testowym: 1.0120
* NajczÄ™stsze bÅ‚Ä™dy: Mylenie SkÅ‚onu ze Staniem (117 przypadkÃ³w), Przysiadu ze Staniem (62 przypadki).

### Model CNN (Bazowy)
* DokÅ‚adnoÅ›Ä‡ na zbiorze testowym: 49.33%
* Strata na zbiorze testowym: 1.0117
* NiÅ¼sza dokÅ‚adnoÅ›Ä‡ niÅ¼ FCN w tym przebiegu. Model czÄ™sto myliÅ‚ klasy Stanie i SkÅ‚on oraz Stanie z Przysiadem.

### Optymalizacje CNN

* **CNN v2 (BatchNorm, More Filters):**
    * DokÅ‚adnoÅ›Ä‡: 44.62%
    * Strata: 3.7451
    * Najgorszy wynik, sÅ‚aba generalizacja na zbiÃ³r testowy mimo dobrej dokÅ‚adnoÅ›ci walidacyjnej.
* **CNN v3 (Augmentation):**
    * DokÅ‚adnoÅ›Ä‡: 53.90%
    * Strata: 1.0241
    * Najlepsza dokÅ‚adnoÅ›Ä‡ w tym przebiegu, nieznacznie przewyÅ¼szajÄ…c FCN. Augmentacja okazaÅ‚a siÄ™ pomocna.
* **CNN v4 (LR Scheduling):**
    * DokÅ‚adnoÅ›Ä‡: 52.82%
    * Strata: 0.9833
    * Wynik zbliÅ¼ony do FCN, gorszy od v3. Redukcja LR nie przyniosÅ‚a poprawy w porÃ³wnaniu do samej augmentacji.

### PorÃ³wnanie Modeli (random_state = 173201)

| Model                      | DokÅ‚adnoÅ›Ä‡ na zbiorze testowym (%) |
| -------------------------- | ------------------------------------ |
| FCN (bazowy)               | 52.55                                |
| CNN (bazowy)               | 49.33                                |
| CNN v2 (BN, More Filters)  | 44.62                                |
| CNN v3 (Augmentation)      | 53.90                                |
| CNN v4 (LR Scheduling)     | 52.82                                |


W tym przebiegu model FCN okazaÅ‚ siÄ™ lepszy od bazowego CNN. Model CNN v3 (Augmentation) osiÄ…gnÄ…Å‚ najlepszy wynik. Augmentacja danych byÅ‚a najbardziej skutecznÄ… technikÄ… optymalizacji. OgÃ³lna dokÅ‚adnoÅ›Ä‡ (max 54%) pozostaje stosunkowo niska.

## ğŸ Podsumowanie i Wnioski

1.  **Niejednoznaczna Przewaga CNN nad FCN:** Bazowy CNN wypadÅ‚ gorzej niÅ¼ FCN w tym przebiegu. Dopiero augmentacja w CNN v3 daÅ‚a nieznacznÄ… przewagÄ™.
2.  **Kluczowa Rola Augmentacji Danych:** Augmentacja (model v3) przyniosÅ‚a najlepszy wynik (53.90%), co sugeruje jej kluczowe znaczenie dla generalizacji.
3.  **Negatywny WpÅ‚yw Innych Optymalizacji w Tej Konfiguracji:** Batch Normalization ze zwiÄ™kszeniem zÅ‚oÅ¼onoÅ›ci (v2) drastycznie pogorszyÅ‚o wynik. LR Scheduling (v4) nie poprawiÅ‚ wyniku wzglÄ™dem samej augmentacji.
4.  **TrudnoÅ›Ä‡ Zadania Klasyfikacyjnego:** Uzyskane dokÅ‚adnoÅ›ci (max ok. 54%) sugerujÄ…, Å¼e zadanie jest wymagajÄ…ce, a mapy nacisku mogÄ… byÄ‡ trudne do rozrÃ³Å¼nienia.
5.  **Znaczenie Walidacji i WpÅ‚yw `random_state`:** Losowy podziaÅ‚ danych ma duÅ¼y wpÅ‚yw na wyniki, co podkreÅ›la potrzebÄ™ np. walidacji krzyÅ¼owej.

---
